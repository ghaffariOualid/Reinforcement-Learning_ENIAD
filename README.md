# ğŸ“˜ Machine Learning II - Reinforcement Learning

### **UniversitÃ©** : Mohamed Premier Oujda  
### **Ã‰cole** : Nationale de l'Intelligence Artificielle et du Digital Berkane  
### **AnnÃ©e universitaire** : 2024 / 2025  
### **Professeur** : [Mohamed Khalifa BOUTAHIR](email@example.com)   
### **Ã‰tudiant** : [Oualid Ghaffari](walid.ghiffario@gmail.com)  
---

## ğŸ“– Introduction  
Ce repository contient une sÃ©rie de **Travaux Pratiques (TP)** sur l'**Apprentissage par Renforcement** (*Reinforcement Learning - RL*). Il couvre :  
âœ… Les algorithmes tabulaires comme **Q-Learning** et **SARSA**.  
âœ… Les mÃ©thodes avancÃ©es comme **Proximal Policy Optimization (PPO)**.  
âœ… Lâ€™implÃ©mentation et lâ€™expÃ©rimentation dans des **environnements simulÃ©s**.  

---

## ğŸ“š Table des MatiÃ¨res  
1. [ğŸ”¹ TP1 - DÃ©couverte d'OpenAI Gym](#[https://github.com/ghaffariOualid/Reinforcement-Learning_ENIAD/blob/main/TP01.ipynb])  
2. [â„ï¸ TP2 - Q-Learning avec FrozenLake](#-tp2---q-learning-avec-frozenlake)  
3. [ğŸš¦ TP3 - Optimisation des Feux de Circulation](#-tp3---optimisation-des-feux-de-circulation)  
4. [ğŸš– TP4 - PPO avec Taxi-v3](#-tp4---ppo-avec-taxi-v3)  
5. [ğŸ“‚ Structure du Repository](#-structure-du-repository)  
6. [ğŸ› ï¸ Installation](#-installation)  
7. [ğŸ¤ Contributions](#-contributions)  
8. [ğŸ“š Ressources](#-ressources)  
---

## ğŸ”¹ TP1 - DÃ©couverte d'OpenAI Gym  

### ğŸ¯ Objectifs  
âœ” Se familiariser avec les environnements **Reinforcement Learning**.  
âœ” Explorer lâ€™environnement **CartPole-v1**.  
âœ” ImplÃ©menter des **politiques alÃ©atoires**.  

### ğŸ“Š RÃ©sultats clÃ©s  
- **ComprÃ©hension** des **espaces d'Ã©tats** et **d'actions**.  
- **Performance des actions alÃ©atoires** : ~20 pas avant Ã©chec.  
- **Visualisation** des **Ã©tats et rÃ©compenses**.  

---

## â„ï¸ TP2 - Q-Learning avec FrozenLake  

### ğŸ¯ Objectifs  
âœ” ImplÃ©menter l'algorithme **Q-Learning**.  
âœ” Comprendre **lâ€™exploration vs exploitation**.  
âœ” Analyser la **convergence de la Q-table**.  

### ğŸ”¢ Algorithme Q-Learning  
$$ Q(s,a) â† Q(s,a) + Î±[r + Î³ \max Q(s',a') - Q(s,a)] $$  

### ğŸ“Š Performances  

| MÃ©trique                        | Valeur |
|---------------------------------|--------|
| Taux de rÃ©ussite (alÃ©atoire)    | 0 %   |
| Taux de rÃ©ussite (aprÃ¨s Q-Learning) | 100%   |
| Ã‰pisodes d'entraÃ®nement         | 5000   |

---

## ğŸš¦ TP3 - Optimisation des Feux de Circulation  

### ğŸ¯ Objectifs  
âœ” Comparer **Q-Learning** (*off-policy*) et **SARSA** (*on-policy*).  
âœ” Optimiser les feux de circulation en **rÃ©duisant le temps dâ€™attente**.  
âœ” ExpÃ©rimenter avec un **environnement personnalisÃ©** []simulant un rÃ©seau routier.    

### ğŸ”¢ Algorithmes  

#### **Q-Learning (off-policy)**  
$$ Q(s,a) â† Q(s,a) + Î±[r + Î³ \max Q(s',a') - Q(s,a)] $$  

#### **SARSA (on-policy)**  
$$ Q(s,a) â† Q(s,a) + Î±[r + Î³ Q(s',a') - Q(s,a)] $$  

### ğŸ“Š Performances  

| Algorithme  | RÃ©duction Temps d'Attente |
|------------|--------------------------|
| Q-Learning | 82%                      |
| SARSA      | 78%                      |

---

## ğŸš– TP4 - PPO avec Taxi-v3  

### ğŸ¯ Objectifs  
âœ” ImplÃ©menter **Proximal Policy Optimization (PPO)**.  
âœ” Tester sur **Taxi-v3** avec **Stable Baselines3**.  

### ğŸ”¢ Fonction objectif avec Clipping  
$$ L(Î¸) = áµœ[\min(r_t(Î¸)A_t, clip(r_t(Î¸), 1-Îµ, 1+Îµ)A_t)] $$  

### ğŸ“Š RÃ©sultats  

| Phase              | Taux de RÃ©ussite | Steps Moyens |
|-------------------|----------------|-------------|
| Avant entraÃ®nement | 0%             | 200+        |
| AprÃ¨s 1000 Ã©pisodes | 92%            | 15.2        |

---

## ğŸ“‚ Structure du Repository  

- **ML2/**  
  - ğŸ“ `TP1/` - DÃ©couverte OpenAI Gym  
  - ğŸ“ `TP2/` - Q-Learning FrozenLake  
  - ğŸ“ `TP3/` - Feux de Circulation  
  - ğŸ“ `TP4/` - PPO Taxi-v3    
  - ğŸ“„ `README.md` - Ce fichier  


---
## âœ… PrÃ©requis  
âœ” **Python 3.x**  
âœ” **pip install --upgrade gymnasium pygame numpy**  

---

## ğŸ“š Ressources  

### ğŸ“– Documentation Officielle  

- ğŸ“Œ [**OpenAI Gymnasium**](https://gymnasium.farama.org/) - Environnements RL standardisÃ©s.  
- ğŸ“Œ [**Stable Baselines3**](https://stable-baselines3.readthedocs.io/) - ImplÃ©mentations avancÃ©es des algorithmes RL.  

### ğŸ“• Livres Fondamentaux  

| ğŸ“˜ Livre | ğŸ”— Lien | ğŸ¯ Focus |
|----------|--------|---------|
| *Reinforcement Learning: An Introduction* (Sutton & Barto) | [ğŸ“„ Lien PDF](http://incompleteideas.net/book/RLbook2020.pdf) | ThÃ©orie RL |
| *Deep Reinforcement Learning Hands-On* (Maxim Lapan) | [ğŸ”— Packt](https://www.packtpub.com/product/deep-reinforcement-learning-hands-on-second-edition/9781838826994) | Pratique avec PyTorch |

---

## ğŸ“ Remarques Finales  

ğŸ“Œ Ce repository couvre les **fondamentaux du Reinforcement Learning** Ã  travers :  

âœ… Des **algorithmes tabulaires** (**Q-Learning, SARSA**).  
âœ… Des **mÃ©thodes avancÃ©es** (**PPO, policy gradient**).  
âœ… Des **applications pratiques** sur des problÃ¨mes rÃ©els.  
âœ… Des **visualisations et comparaisons** pour mieux comprendre chaque approche.  

Nous espÃ©rons que ces ressources vous aideront dans votre apprentissage du **Reinforcement Learning** ! ğŸ’¡ğŸ”¥
